{
  "name": "nf160nb10_QF10_DinputConcat_Verif0_85correct_noRefLoss_DCT" // "nf160nb10_QF10_MSEandHalfD_DlayerNorm_nf16nb8_GnoNorm_LR1e-4"
  , "use_tb_logger": false
  , "model":"dncnn"
//  , "scale": 4
  , "gpu_ids": [0]
  , "range": [0,255]

  , "datasets": {
    "train": {
      "name": "DIV2K"
      , "mode": "JPEG"
      , "jpeg_quality_factor": 10 //[[5,50]] //[5,10,20,30,40,50,60,70]
      , "dataroot_Uncomp": "DIV2K_train/DIV2K_train_sub_GrayScale.lmdb"
      , "subset_file": null
      , "use_shuffle": true
      , "n_workers": 0
      , "batch_size": 16
      , "batch_size_4_grads_G": 16
      , "batch_size_4_grads_D": 16
      , "patch_size": 256
      , "use_flip": true
      , "use_rot": true
    }
    , "val": {
      "name": "val_set14_part"
      , "mode": "JPEG"
      , "jpeg_quality_factor": 10 //[[5,50]] //[5,10,20,30,40,50,60,70]
      , "dataroot_Uncomp": "Set14/Set14_GrayScale" //"DIV2K_valid/DIV2K_valid_HRx4"//"Set14"
    }
  }

  , "path": {
    "root": "/media/ybahat/data/projects/SRGAN"
//    , "pretrain_model_G": "/media/ybahat/data/projects/SRGAN/experiments/JPEG/nf160nb10_QF10_LR1e-4/models/550142_G.pth" //,"../pretrained_models/RRDB_ESRGAN_x4.pth" //,"../pretrained_models/RRDB_PSNR_x4.pth"
//    , "pretrain_model_G": "../pretrained_models/chroma_DCTnf160nb10QF10_G.pth"
    , "pretrain_model_G": "../pretrained_models/DCTnf160nb10QF10_G.pth"
    , "Y_channel_model_G": "/media/ybahat/data/projects/SRGAN/experiments/JPEG/nf160nb10_QF10_SymmetricWGAN_DinputConcat_InitialVerific_noRefLoss_DCT_BatchInstanceNorm_fromMSE_lr1e-5/models/2000001_G.pth"
//    , "pretrain_model_D": "../pretrained_models/NonConcatDCTnf160nb10QF10_verifiedD.pth"
//    , "pretrain_model_G": "../experiments/JPEG/nf160nb10_QF10_SymmetricWGAN_Dverific_noRefLoss_DCT_BatchInstanceNorm_fromMSE_lr1e-5/models/456439_G.pth"
//    , "pretrain_model_D": "../pretrained_models/ConcatInputDCTnf160nb10QF10_verifiedD.pth"
//    , "pretrain_model_D": "../pretrained_models/NonConcatDCTnf160nb10QF10_verifiedD.pth"
//      , "pretrain_model_D": "../pretrained_models/chroma_ConcatInputDCTnf160nb10QF10_verifiedD.pth"
}

  , "network_G": {
    "which_model_G": "DnCNN" // RRDB_net | sr_resnet
    , "latent_input": "None" // "all_layers" //"all_layers","first_layer","None"
    , "latent_channels": 64 //"SVDinNormedOut_structure_tensor" //,"STD_1dir" //2,"STD_directional","structure_tensor","SVD_structure_tensor"
    , "norm_type": "batch" //"instance" //"batch"
    , "mode": "CNA"
    , "nf": 160
    , "nb": 10 //17
    , "in_nc": 64
    , "out_nc": 64
    , "gc": 32
    , "group": 1
  }
  , "network_D": {
    "which_model_D": "DnCNN_D" //"DnCNN_D_SN" //,"DnCNN_D" //,"PatchGAN"
    , "relativistic": 0
    , "concat_input": 1
    , "inject_Z": 0 //1
    , "DCT_D": 1
    , "pre_clipping": 0 //1
    , "add_quantization_noise": 0 //1
    , "norm_type": "batch"
    , "act_type": "leakyrelu"
    , "mode": "CNA"
//    , "nf": 16 //64
//    , "in_nc": 1
  }

  , "train": {
    "resume":1
    ,"lr_G": 1e-5 //1e-5 //1e-4
    , "weight_decay_G": 0
    , "beta1_G": 0.9
    , "lr_D": 1e-5 //1e-4 //1e-5
    , "lr_E": 1e-4
//    , "lr_latent": 1e-5
    , "weight_decay_D": 0
    , "beta1_D": 0.9
    , "lr_scheme": "MultiStepLR"
    , "steps_4_loss_std": 500
    , "std_4_lr_drop": 1e6 //1.6
    , "lr_change_ratio": 4 // ratio between STD and slope of linear fit, under which lr is reduced
    , "lr_steps": [50000, 100000, 200000, 300000] //[5000, 10000, 20000, 30000] //
    , "lr_gamma": 0.5
//    , "pixel_domain": "HR"
    , "pixel_criterion": "l1"
//    , "feature_domain": "HR"
    , "feature_criterion": "l1"
    , "gan_type": "wgan-gp" //,"vanilla","lsgan","wgan-gp"
    , "optimalZ_loss_type": "l1"  //"None","hist","l1"
    , "D_verification": "past" //'current', 'convergence', 'past','initial','initial_gradual'
    , "steps_4_D_convergence": 2000
    , "min_D_prob_ratio_4_G": 0.01 //0.01 //1.05 //1.1//Average D prob ratio should be at least this on all preceeding D_valid_Steps_4_G_update steps
    , "min_mean_D_correct": 0.85 //0.85 //0.1 //At least this portion of images should be correctly classified by D in all preceeding D_valid_Steps_4_G_update steps.
    , "D_update_ratio": 10 //0
    , "D_valid_Steps_4_G_update": 10 //Perform G steps using l_gan only when D was successfull in previous D_update_ratio steps
    , "CEM_exp": 0 //Means I use loss mask and padding while training and testing, no matter if DTE_arch or not.

    , "pixel_weight": 0 //1e-3 //1e-2
    , "feature_weight": 0 //1
    , "gan_weight": 5e-3 //1 //5e-3
    , "latent_weight": 0 //5e-3 //1 //Weight on loss between G's output and the desired criterion given Z. Previously: Weight on loss on difference between z and the output of E(G(LR,z))
    , "optimalZ_loss_weight": 0 //1e-4 //0 //100
    , "range_weight": 1 //0 //5000

    //for wgan-gp
    // , "D_update_ratio": 1
     , "D_init_iters": 0
     , "E_init_iters": 40000
     , "gp_weigth": 10

    , "manual_seed": 0
    , "niter": 2e6 //23532 //500100 //5e5
    , "val_freq": 5e2
    , "val_save_freq": 1e4
}

  , "logger": {
    "print_freq": 500 //200
    , "save_checkpoint_freq": 20 // Minutes//5e3
  }
}
